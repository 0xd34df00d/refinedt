\documentclass[a4paper]{article}
\usepackage{a4wide}
\usepackage[utf8]{inputenc}
\usepackage[T2A]{fontenc}
\usepackage{amsmath,amsfonts,amssymb,amsthm}
\usepackage{mathtools}
\usepackage{xcolor}
\usepackage{ottalt}
\usepackage{subcaption}
\usepackage{cite,url,babelbib}
\usepackage[english]{babel}

\addtolength{\topmargin}{-1.05in}
\addtolength{\textheight}{1.55in}

\newtheorem{theorem}{Theorem}
\newtheorem{lemma}{Lemma}

\newcommand{\unit}{u}
\newcommand{\Unit}{\textbf{Unit}}
\newcommand{\unitc}{\hat{u}}
\newcommand{\Unitc}{\widehat{\textbf{Unit}}}
\newcommand{\Int}{\textbf{Int}}
\newcommand{\ctxok}{\text{~ok}}

\begin{document}

\newNTclass{nonterm}
\newnonterm e \varepsilon
\newnonterm{es}{\varepsilon}
\newnonterm{ec}{\hat\varepsilon}
\newnonterm r \rho
\newnonterm{ts}{\tau}
\newnonterm{tc}{\hat\tau}
\newnonterm s s
\newnonterm l l
\newnonterm B B
\newnonterm G \Gamma
\newnonterm{GC}{\hat\Gamma}
\newnonterm{binop}{\odot}

\newNTclass{gterm}
\newgterm x x
\newgterm v v
\newgterm n n

\newcommand{\figref}[1]{Figure \ref{fig:#1}}

\inputott{surface.ott}

\title{Compiling refinement types to dependent types}

\maketitle

\section{Introduction}

\section{Overview}

%TODO describe the notion of the oracle (like an SMT solver) and what we expect of the oracle.

\section{Calculi definitions}

\subsection{Surface language}

Our surface language is based on simply typed lambda calculus.
Refinements over the types are, of course, the most important extension.
The other ones are:
\begin{itemize}
  \item dependent arrow types, to allow subsequent refinements refer preceding arguments,
  \item limited form of algebraic data types and dependent pattern matching
    insired by \cite{TAPLVariants,Eisenberg16},
    to illustrate reasoning about those widely used constructs.
\end{itemize}

The syntax of the surface language is presented in \figref{surface_syntax}.

The typing rules for the surface language are laid out in \figref{surface_typing}.
For the type well-formedness and term typing rules
we also assume each of them has a premise $\nonterm G \ctxok$
stating that the context is well-formed.

\begin{figure}[ht]
  \footnotesize
  \begin{subfigure}{.6\textwidth}
    \nonterms{es,l}
    \caption{Term level}
  \end{subfigure}
  \begin{subfigure}{.5\textwidth}
    \nonterms{G,r,B,ts}
    \caption{Type level}
  \end{subfigure}
  \caption{Surface language syntax}
  \label{fig:surface_syntax}
\end{figure}

\begin{figure}[ht]
  \footnotesize
  \drules[TCTX]{$\nonterm G \ctxok$}{context well-formedness}{Empty,Bind}
  \drules[TWF]{$\nonterm G \vdash \nonterm{ts}$}{type well-formedness}{TrueRef,Base,Conj,Arr,Rec}
  \drules[T]{$\nonterm G \vdash \nonterm{es} : \nonterm{ts}$}{term typing}{Unit,Var,Abs,App,Case,Con,Sub}
  \drules[ST]{$\nonterm G \vdash \nonterm{ts}_1 <: \nonterm{ts}_2$}{subtyping}{Base,Arr}
  \caption{Surface language typing}
  \label{fig:surface_typing}
\end{figure}

We introduce a shorthand notation $\top$ denoting some tautology
which we use for trivial refinements that do not carry any extra information.
In particular, one good way to define $\top$ is
to state the equality of the sole inhabitant of $\Unit$ to itself:
$\top \triangleq \unit = \unit$.

The surface language might also have other base types (for example, $\Int$),
elements of syntax (like numbers and operations on them)
as well as typing rules relating those,
but we omit them for the sake of brevity.

We also have the following concessions:
\begin{itemize}
  \item The syntax only allows refinements on base types.
    Note that this does not restrict the expressive power of the language.
    For instance, a refinement on a function that we might otherwise wish to write as
    \[
      (x : \Int) \rightarrow \{ v : \Int \rightarrow \Int | v x = 0 \} \rightarrow \Int
    \]
    might instead be expressed via a dummy parameter:
    \[
      (x : \Int) \rightarrow (f : \Int \rightarrow \Int) \rightarrow \{ \_ : \Unit | f x = 0 \} \rightarrow \Int.
    \]
  \item Our algebraic data types only allow a single ``field'' in each constructor.
    One way to alleviate this is to introduce tuples,
    but doing so would complicate the exposition
    without any benefit for illustrating the main idea of this work.
\end{itemize}

The translation function $[|\ |]$ maps the typing context $\nonterm G$ to some logic
that the oracle can handle.
It might be defined as follows:
\begin{equation}
\begin{aligned}
  & [|\ \emptyset\ |]                                         && \triangleq && \top																						            \\
  & [|\ \nonterm G, x : \{ v : \nonterm B | \nonterm r \}\ |] && \triangleq && [|\ \nonterm G\ |] \land [|\ [ v \mapsto x ] \nonterm r\ |]  \\
  & [|\ \nonterm r_1 \land \nonterm r_2\ |]                   && \triangleq && [|\ \nonterm r_1\ |] \land [|\ \nonterm r_2\ |]              \\
  & [|\ \nonterm{es}_1 = \nonterm{es}_2\ |]                   && \triangleq && \text{oracle}(\nonterm{es}_1 = \nonterm{es}_2)             \\
\end{aligned}
\end{equation}

The last equation represents the assumption
that the oracle knows how to translate the atomic refinements.

%TODO define substitutions on the \nonterm r

In the subsequent text we also assume the oracle can decide the resulting proposition
(otherwise it might be left as a separate lemma to be filled out by the user in the core language, or rejected altogether).

\subsection{Core language}

We take $\lambda C$ \cite{TTFPLambdaC}
with a unit type as our core dependently typed language.
We conjecture that the introduction of units
does not break the usual metatheoretical properties of the system.

The syntax of the core language is presented in \figref{core_syntax},
and the typing rules are defined in \figref{core_typing}.

\begin{figure}[ht]
  \footnotesize
  \nonterms{ec,s}
  \caption{Core language syntax}
  \label{fig:core_syntax}
\end{figure}

\begin{figure}[ht]
  \footnotesize
  \drules[CT]{$\nonterm G \vdash \nonterm{ec}_1 : \nonterm{ec}_2$}{core typing}{Sort,UnitType,UnitTerm,Var,Weaken,Form,App,Abs,Conv}
  \caption{Core language typing rules}
  \label{fig:core_typing}
\end{figure}

Although the syntax doesn't mention $\tau$, we will use it as a metavariable
where a type (an inhabitant of $\star$) is expected.

\newcommand{\dast}{\ **\ }

We also establish some derived forms in the core language to simplify the subsequent exposition:

\begin{itemize}
  \item Simplified variable typing rule which we call \ranchor{CT-VarW}:
    \[
      \inferrule{\nonterm{GC} \vdash \nonterm{ec} : s \\ \gterm x : \nonterm{ec} \in \nonterm{GC}}
                {\nonterm{GC} \vdash \gterm x : \nonterm{ec}}.
    \]
    This rule unfolds into a single \ranchor{CT-Var} defining $x$,
    followed by a sequence of \ranchor{CT-Weaken}
    to ``move'' the $x$ into the right position in the final $\nonterm{GC}$.
  \item Non-dependent function type:
    \[
      \tau_1 \rightarrow \tau_2 \triangleq \Pi \_ : \tau_1. \tau_2.
    \]
  \item Dependent pair type, or $\Sigma$-type, with the first component being a value $x$ of type $\tau$ and the second component being of type $P x$:
    \[
      (x : \tau \dast P x) \triangleq \Pi \alpha : \star. (\Pi x : \tau. P x \rightarrow \alpha) \rightarrow \alpha,
    \]
    with the corresponding constructor (we overload the syntax here to resemble Idris):
    \[
      (x \dast p) \triangleq \lambda \alpha : \star. \lambda f : (\Pi x' : \tau. P x' \rightarrow \alpha). f x p
    \]
    and projections
    \[
      \text{fst} \triangleq \lambda \sigma : (x : \tau \dast P x). \sigma \tau (\lambda x' : \tau. \lambda \_ : P x'. x'),
    \]
    \[
      \text{snd} \triangleq \lambda \sigma : (x : \tau \dast P x). \sigma \tau (\lambda x' : \tau. \lambda p : P x'. p).
    \]
  \item Non-dependent pair type:
    \[
      (\tau_1, \tau_2) \triangleq \{ x : \tau_1\ **\ (\lambda \_ : \tau_1. \tau_2) x \}.
    \]
  \item Equality of expressions $\nonterm{ec}_1, \nonterm{ec}_2$ of type $S$:
    \[
      \nonterm{ec}_1 \equiv \nonterm{ec}_2 \triangleq \Pi P : S \rightarrow \star. (P x \rightarrow P y, P y \rightarrow P x).
    \]
    The reader might recognize this as the Leibniz equality \cite{FindSomethingForThis}.
  \item ADTs, expressed using an encoding similar to Boehm-Berarducci's \cite{Bohm85}.
    We borrow the syntax for the ADTs from the surface language and put a hat on it,
    so let's take some ADT $\widehat{\langle \overline{l_i : \nonterm{ts}_i}^i \rangle}$.
    The usual Boehm-Berarducci encoding associates the type
    $\Pi \alpha : \star. \overline{(\nonterm{ts}_i \rightarrow \alpha)}^i \rightarrow \alpha$ with it.

    We go a step further to account for the subset of the dependent pattern matching
    that we are interested in.

    First, each label $l_i$ gives rise to a term $\hat{l_i}$ of type $\nonterm{ts}_i \rightarrow \xi$.
    %TODO operational semantics?
    We then define the derived form
    \[
      \widehat{\langle \overline{l_i : \nonterm{ts}_i}^i \rangle}
        \triangleq
          \Pi s : \xi.
          \Pi \alpha : \star.
          \overline{(\Pi x_i : \nonterm{ts}_i. s \equiv \hat{l_i} x_i \rightarrow \alpha)}^i \rightarrow \alpha.
    \]
    The outer extra argument named $s$ denotes the scrutinee of the case expression to be defined next.
    The inner extra argument with the type $s \equiv \hat{l_i} x_i$
    expresses the subset of dependent pattern matching
    that we rely on for the translation from the surface language:
    in particular, it provides the ``case branch'' with a proof
    that the scrutinee $s$ is indeed equal to the ``case pattern'' $\hat{l_i} x_i$.
\end{itemize}

\section{Translation}

\newcommand{\tranty}{\mu_\tau}
\newcommand{\tranterm}{\mu_\varepsilon}

\newcommand{\Tranctx}{\mu_{\vdash\Gamma}}
\newcommand{\Tranty}{\mu_{\vdash\tau}}
\newcommand{\Tranterm}{\mu_{\vdash\varepsilon}}

The surface language ultimately gets translated into the core language.
What really matters for practical purposes is the translation of the terms since
terms, not types or contexts, will eventually be compiled down to some executable code.
On the other hand, it seems desirable to ensure that the terms
that are well-typed in the surface language
are accepted by the core type checker after the translation,
since this provides some level of guarantee that the translation ``makes sense''.

In particular, note that the oracle plays a crucial role in typechecking of the surface language,
so it is natural to expect that its output will also be used during any such translation,
for instance, to produce core language proofs that VCs hold.
The only trace of the oracle's work is in the typing derivation
(namely, in the subtyping relation check and the \ranchor{T-Sub} typing rule),
so we choose to do the translation not on \emph{terms},
but rather on \emph{well-typedness derivations} for the terms.
This way the oracle has a chance to enrich the original surface language term
with proofs and witnesses of whatever it decided.

Thus the ultimate goal of this section is to define a function $\Tranterm$
taking a typing derivation in the surface language
and producing a typing derivation in the core language.
As part of its duty
this function also needs to translate the types and contexts
encountered in the source derivation,
so we also define two helper functions.
$\Tranty$ takes a surface derivation of a \emph{type} well-formedness
and produces the corresponding core derivation.
$\Tranctx$ takes a surface derivation of a \emph{context} well-formedness
and produces a core language context.

We also define two helper functions, $\tranty$ and $\tranterm$,
invoking $\Tranty$ and $\Tranterm$ and extracting just the type and term component respectively.

All in all, our goal is to define $\Tranctx$, $\Tranty$ and $\Tranterm$
with ``metatypes''
\begin{align*}
  \Tranctx  & : \nonterm G \ctxok                             \longmapsto \nonterm{GC},                                     \\
  \Tranty   & : \nonterm G \vdash \nonterm{ts}                \longmapsto \nonterm{GC} \vdash \nonterm{tc} : \star,         \\
  \Tranterm & : \nonterm G \vdash \nonterm{es} : \nonterm{ts} \longmapsto \nonterm{GC} \vdash \nonterm{ec} : \nonterm{tc},
\end{align*}
Our helper functions $\tranty$ and $\tranterm$ are then defined to return the $\nonterm{tc}$ and $\nonterm{ec}$
from the right-hand sides above respectively.

The apparent asymmetry of $\Tranctx$, which does not produce a derivation as others do,
is due to our core language not having a separate notion of a context well-formedness.

\paragraph{Contexts.}
As a warm-up,
we start with defining $\Tranctx$,
which is the simplest of the three.
It merely maps the types of the bindings in a (well-formed) context
from the surface language into the core language.

Since $\Tranctx$ is defined on the derivations of $\nonterm G \ctxok$,
we consider the last rule used in a derivation:
\begin{itemize}
  \item \ranchor{TCTX-Empty}.
    \begin{align*}
      & \inferrule{~}
                  {\emptyset \ctxok}
          \longmapsto
        \emptyset.
    \end{align*}
    The base case is trivial: we map the empty context to the empty context.
  \item \ranchor{TCTX-Bind}.
    \begin{align*}
      & \inferrule{\nonterm G \ctxok \\ \nonterm G \vdash \nonterm{ts}}
                  {\nonterm G , \gterm x : \nonterm{ts} \ctxok}
          \longmapsto
        \Tranctx(\nonterm G \ctxok), x : \tranty(\nonterm G \vdash \nonterm{ts}).
    \end{align*}

    We recurse on the prefix $\nonterm G$,
    which is admissible due to the $\nonterm G \ctxok$ premise,
    and we use $\tranty$ to get the translated type of $\gterm x$,
    which is also admissible due to the other premise.
\end{itemize}

\paragraph{Types.}
$\tranty$ is defined as follows,
with the slight abuse of notation to allow ``recursive'' calls
on the refinement part of the surface language syntax:
\begin{equation}
\begin{aligned}
  & \tranty( (x : \nonterm{ts}_1) \rightarrow \nonterm{ts}_2)  && \triangleq \Pi x : \tranty(\nonterm{ts}_1). \tranty(\nonterm{ts}_2)     \\
  & \tranty( \{ v : \nonterm{ts} | \nonterm{r} \})             && \triangleq \{ v : \tranty(\nonterm{ts})\ **\ \tranty(\nonterm r) \}     \\
  & \tranty( \nonterm r_1 \land \nonterm r_2 )                 && \triangleq ( \tranty(\nonterm r_1) , \tranty(\nonterm r_2))             \\
  & \tranty( \nonterm{es}_1 = \nonterm{es}_2 )                 && \triangleq \tranterm(\nonterm{es}_1) \equiv \tranterm(\nonterm{es}_2)   \\
  & \tranty(B)                                                 && \triangleq B                                                            \\
%TODO this last one is not well-defined
\end{aligned}
\end{equation}
Or, in words:
\begin{itemize}
  \item (dependent) arrow types are translated to the corresponding $\Pi$-types,
  \item refined types are translated to the corresponding $\Sigma$-types,
  \item atomic refinements, being propositions about surface language terms equality,
    are translated to propositions stating the equality of translated core language terms,
  \item conjunctions of several (atomic) refinements are represented as tuples of the corresponding atomic translations.
\end{itemize}

\paragraph{Terms.}
Finally we define $\Tranterm$.
We consider the term typing rule that is at the root of the derivation tree for $\nonterm G \vdash \nonterm{es} : \nonterm{ts}$.

\begin{itemize}
  \item \ranchor{T-Unit}.
    \begin{align*}
      & \inferrule{\nonterm G \ctxok}
                  {\nonterm G \vdash \unit : \{ \gterm v : \Unit | \top \}}
          \longmapsto
        \inferrule{~}
                  {\nonterm{GC} \vdash \unitc : \Unitc}, \\
      \text{where}~&\nonterm{GC} = \Tranctx(\nonterm G \ctxok).
    \end{align*}
    This rule has a single premise $\nonterm G \ctxok$ that the surface context is well-formed.
    We use $\Tranctx$ to translate the surface derivation of that premise into the core one,
    and extract the resulting context $\nonterm{GC}$.
    We then use that context for \ranchor{CT-UnitTerm}.

  \item \ranchor{T-Var}.
    \begin{align*}
      & \inferrule{\nonterm G \ctxok \\
                   \gterm x : \nonterm{ts} \in \nonterm G}
                  {\nonterm G \vdash \gterm x : \nonterm{ts}}
          \longmapsto
        \inferrule{x : \nonterm{tc} \in \nonterm{GC}}
                  {\nonterm{GC} \vdash \gterm x : \nonterm{tc}},    \\
      \text{where}~&\nonterm{GC} = \Tranctx(\nonterm G \ctxok),       \\
                   &\nonterm{tc} = \tranty(\Gamma \vdash \nonterm{ts}).
    \end{align*}

    To show that the right-hand side is well-defined,
    we need to show that $x : \nonterm{tc} \in \nonterm{GC}$ holds.

    By definition of $\Tranctx$,
    if $\nonterm G$ contains a binding for the name $x$,
    then $\nonterm{GC}$ also contains a binding for that name,
    and its type is precisely $\tranty(\Gamma \vdash \nonterm{ts})$.
    Thus, we are allowed to use the (derived) core typing rule \ranchor{CT-VarW}.
\end{itemize}

Having defined these functions, we formulate a simple but useful lemma:
\begin{lemma}[Translation totality]
  $\Tranctx$, $\Tranty$ and $\Tranterm$ are total.
\end{lemma}
\begin{proof}
  Firstly, each function is defined for all possible inputs.
  Then, each function recurses on structurally smaller inputs,
  and, since derivation trees are finite,
  this implies each function terminates for any input.
\end{proof}

\subsection{Correctness}

The correctness of the translation hinges on two key theorems.
The first one claims that a well-typed program in surface language remains well-typed after the translation to the core language.
The second one claims that a well-typed surface language program evaluates to ``the same'' value as the translated one.

\begin{theorem}[Well-typedness preservation]
  For any well-typed surface language term $\nonterm{es}$,
  the result of the translation $\tranterm(\nonterm{es})$ is ``equivalently'' typeable in the core language.
\end{theorem}
\begin{proof}
  This follows directly from the definition of $\tranterm$ via $\Tranterm$,
  the latter being total and mapping onto typing derivations in the core language.
\end{proof}

\begin{theorem}[Evaluation equivalence]
  If a well-typed surface language term $\nonterm{es}$ evaluates to v, then $\tranterm(\nonterm{es})$ evaluates to $\tranterm(v)$:
  %TODO symbols and all that for v
\end{theorem}
\begin{proof}
\end{proof}

\bibliographystyle{babunsrt-lf}
\bibliography{biblio}

\end{document}
